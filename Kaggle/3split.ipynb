{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6749, 24), (6749,), (199, 24), (199,), (426, 24))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# get data and labels\n",
    "train_data = train.drop(['Target Variable (Discrete)'], axis=1)\n",
    "train_labels_ = train['Target Variable (Discrete)']\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "train_data_ = scaler.fit_transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "# set numpy random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer.fit(train_data_)\n",
    "train_data_ = imputer.transform(train_data_)\n",
    "test_data = imputer.transform(test_data)\n",
    "    \n",
    "# split data into train and validation\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data_, train_labels_, test_size=0.2)\n",
    "# train_data, train_labels = train_data_, train_labels_\n",
    "\n",
    "# oversample\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler()\n",
    "train_data, train_labels = oversample.fit_resample(train_data, train_labels)\n",
    "\n",
    "# # print shapes\n",
    "train_data.shape, train_labels.shape, val_data.shape, val_labels.shape, test_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([447, 488, 423, 398, 398, 405, 408, 399, 402, 397, 397,   1, 397,\n",
       "       398, 398, 398, 397, 397])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(train_labels) + np.bincount(val_labels, minlength=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "subclasses = [\n",
    "    [0, 1, 2, 5, 6, 9, 10, 11, 12, 14, 16, 17],\n",
    "    [3, 4, 7, 8, 13, 15]\n",
    "]\n",
    "\n",
    "def train_differentiator(subclasses):\n",
    "    # decides which subclass to use\n",
    "\n",
    "    labels_tmp = train_labels.copy()\n",
    "    for i in range(len(subclasses)):\n",
    "        keeps = subclasses[i]\n",
    "        mask = np.isin(train_labels, keeps)\n",
    "        labels_tmp[mask] = i\n",
    "\n",
    "    # train knn\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(train_data, labels_tmp)\n",
    "\n",
    "    # train random forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "    rf.fit(train_data, labels_tmp)\n",
    "\n",
    "    return knn, rf\n",
    "\n",
    "\n",
    "def train_subclass(subclass):\n",
    "\n",
    "    mask = np.isin(train_labels, subclass)\n",
    "\n",
    "    train_data_tmp = train_data[mask]\n",
    "    labels_tmp = train_labels[mask]\n",
    "\n",
    "    # train knn\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(train_data_tmp, labels_tmp)\n",
    "\n",
    "    # train random forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "    rf.fit(train_data_tmp, labels_tmp)\n",
    "\n",
    "    return knn, rf\n",
    "\n",
    "differentiator_knn, differentiator_rf = train_differentiator(subclasses)\n",
    "subclass_models = []\n",
    "for subclass in subclasses:\n",
    "    subclass_models.append(train_subclass(subclass))\n",
    "\n",
    "def predict_combined(data):\n",
    "    diff_preds = differentiator_rf.predict(data)\n",
    "    subclass_preds = []\n",
    "    for i in range(len(subclass_models)):\n",
    "        knn, rf = subclass_models[i]\n",
    "        subclass_preds.append(rf.predict(data))\n",
    "\n",
    "    final_preds = np.zeros(len(data))\n",
    "\n",
    "    for i in range(len(subclasses)):\n",
    "        subclass = subclasses[i]\n",
    "        mask = np.isin(diff_preds, i)\n",
    "        final_preds[mask] = subclass_preds[i][mask]\n",
    "        \n",
    "    return final_preds.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined accuracy: 0.8442211055276382\n",
      "Combined f1: 0.4549076716631934\n"
     ]
    }
   ],
   "source": [
    "preds = predict_combined(val_data)\n",
    "acc = accuracy_score(val_labels, preds)\n",
    "f1 = f1_score(val_labels, preds, average='macro')\n",
    "print(f'Combined accuracy: {acc}')\n",
    "print(f'Combined f1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  2  1  1  1  2  1  5  1  0  1  6  0  1  2  0  2  1  2  1  5  5  1  2\n",
      "  0  2  6  0  1  0  1  1  2  6  1  0  6  0  0  5  1  1  1  1  0  4  1  0\n",
      "  6  1  2  1  1  1  1  1  6  2  0  0  1  1  1  6  1  1  2  2  1  2  1  2\n",
      "  1  1  6  1  1  1  1  1  1  2  0  4  6  0  1  1  1  1  1  0  8  2  1  2\n",
      "  0  1  2  0  1  0  0  1  1  1  1  2  0  8  1  0  0  0  0  6  0  1  2  1\n",
      "  0  1  1  1  6  1  1  2  1  1  1  1  1  0  0  2  2  2  1  0  0  1  0  2\n",
      "  1  1  6  2  3  0  1  1  6  1  1  1  1  0  1  1  0  1  0  0  2  1  0  0\n",
      "  0  1  0  0  1  1  1  1  1  1  0  0  2  5  1  1  2  1  1  5  4  1  5  0\n",
      "  1  6  1  1  0  2  1  1  1  0  1  6  1  1  1  0  1 14  0  0  0  0  2  1\n",
      "  1  0  1  1  1  1  0  1  1  6  1  1  0  2  2  1  1  5  1  0  2  1  0  0\n",
      "  0  1  1  5  6  5  1  6  0  1  0 15  1  1  1  2  0  0  0  1  6  1  1  0\n",
      "  0  0  0  0  0  0  0  0  1  8  5  6  0  0  3  1  1  1  1  5  5  1  2  1\n",
      "  0  1  0  1  1  6  0  5  0  1 14  0  1  1  1  1  2  1  1  1  6  1  2  1\n",
      "  2  0  1  1  2  2  2  1  1  1  0  0  2  0  1  0  1  1  0  0  1  1  1  1\n",
      "  1  1  1  1  0  1  1  1  0  2  0  0  1  1  1  1  2  5  1  2  0  6  2  6\n",
      "  2  1  2  0  6  0  1  0  1  0  1  1  1  1  0  1  1  1  0  1  2  1  2  2\n",
      "  1  0  8  1  1  1  1  2  0  2  1  1  5  1  4  2  1  1  6  2  2  0  1  1\n",
      "  1  1  1  1  2  1  1  1  0  8  0  1  0  1  1  1  1  0]\n",
      "[105 206  58   2   4  16  27   0   5   0   0   0   0   0   2   1]\n"
     ]
    }
   ],
   "source": [
    "preds = predict_combined(test_data)\n",
    "\n",
    "print(preds)\n",
    "print(np.bincount(preds))\n",
    "\n",
    "# save predictions\n",
    "preds = pd.DataFrame(np.array([(i + 1, v) for i, v in enumerate(preds)]))\n",
    "preds.columns = ['Id', 'Category']\n",
    "preds.to_csv('3split_preds.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
