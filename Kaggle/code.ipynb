{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import everything\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((795, 24), (795,), (199, 24), (199,), (426, 24))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# get data and labels\n",
    "train_data = train.drop(['Target Variable (Discrete)'], axis=1)\n",
    "train_labels = train['Target Variable (Discrete)']\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data_ = scaler.transform(train_data)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data_, train_labels, test_size=0.2, random_state=42)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "\n",
    "# print shapes\n",
    "train_data.shape, train_labels.shape, val_data.shape, val_labels.shape, test_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([249, 488, 109,   3,   3,  41,  70,   5,   7,   2,   1,   1,   1,\n",
       "         3,   5,   4,   1,   1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(train_labels) + np.bincount(val_labels, minlength=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "all_imp = imputer.fit_transform(train_data_)\n",
    "train_data_imp = imputer.transform(train_data)\n",
    "val_data_imp = imputer.transform(val_data)\n",
    "test_data_imp = imputer.transform(test_data)\n",
    "# train_data_imp.shape\n",
    "for i in train_data_imp:\n",
    "    for j in i:\n",
    "        if np.isnan(j):\n",
    "            print('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/abhay/Code/Courses/FOML/Assignments/Kaggle/code.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/abhay/Code/Courses/FOML/Assignments/Kaggle/code.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# chi2\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/abhay/Code/Courses/FOML/Assignments/Kaggle/code.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m chi2_selector \u001b[39m=\u001b[39m SelectKBest(chi2, k\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/abhay/Code/Courses/FOML/Assignments/Kaggle/code.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m chi2_selector\u001b[39m.\u001b[39;49mfit(train_data_imp, train_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/abhay/Code/Courses/FOML/Assignments/Kaggle/code.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m chi2_support \u001b[39m=\u001b[39m chi2_selector\u001b[39m.\u001b[39mget_support()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/abhay/Code/Courses/FOML/Assignments/Kaggle/code.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m chi2_feature \u001b[39m=\u001b[39m train_data_imp\u001b[39m.\u001b[39mloc[:,chi2_support]\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:503\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    498\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    499\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m], multi_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    500\u001b[0m )\n\u001b[1;32m    502\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params(X, y)\n\u001b[0;32m--> 503\u001b[0m score_func_ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore_func(X, y)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(score_func_ret, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscores_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpvalues_ \u001b[39m=\u001b[39m score_func_ret\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:231\u001b[0m, in \u001b[0;36mchi2\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m X \u001b[39m=\u001b[39m check_array(X, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39m(np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32))\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many((X\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m issparse(X) \u001b[39melse\u001b[39;00m X) \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput X must be non-negative.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[39m# Use a sparse representation for Y by default to reduce memory usage when\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39m# y has many unique classes.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m Y \u001b[39m=\u001b[39m LabelBinarizer(sparse_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mfit_transform(y)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative."
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# chi2\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, k=10)\n",
    "chi2_selector.fit(train_data_imp, train_labels)\n",
    "chi2_support = chi2_selector.get_support()\n",
    "chi2_feature = train_data_imp.loc[:,chi2_support].columns.tolist()\n",
    "print(str(len(chi2_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3774690855196913"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn classifier\n",
    "\n",
    "# grid search\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=5)\n",
    "knn_gscv.fit(train_data_imp, train_labels)\n",
    "nn = knn_gscv.best_params_\n",
    "\n",
    "# find accuracy\n",
    "knn = KNeighborsClassifier(n_neighbors=nn['n_neighbors'])\n",
    "knn.fit(train_data_imp, train_labels)\n",
    "knn_pred = knn.predict(val_data_imp)\n",
    "accuracy_score(val_labels, knn_pred)\n",
    "f1_score(val_labels, knn_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3572219315076458"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax classifier\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(train_data_imp, train_labels)\n",
    "logreg_pred = logreg.predict(val_data_imp)\n",
    "accuracy_score(val_labels, logreg_pred)\n",
    "f1_score(val_labels, logreg_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4727839505189698"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try with random forests\n",
    "\n",
    "# grid search\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = {'n_estimators': np.arange(1, 250)}\n",
    "rf_gscv = GridSearchCV(rf, param_grid, cv=5)\n",
    "rf_gscv.fit(train_data_imp, train_labels)\n",
    "nn = rf_gscv.best_params_\n",
    "\n",
    "est = nn['n_estimators']\n",
    "# find accuracy\n",
    "rf = RandomForestClassifier(n_estimators=nn['n_estimators'])\n",
    "rf.fit(train_data_imp, train_labels)\n",
    "rf_pred = rf.predict(val_data_imp)\n",
    "accuracy_score(val_labels, rf_pred)\n",
    "f1_score(val_labels, rf_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4067353865231955"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC\n",
    "\n",
    "# grid search\n",
    "svc = SVC()\n",
    "param_grid = {'C': np.arange(1, 25)}\n",
    "svc_gscv = GridSearchCV(svc, param_grid, cv=5)\n",
    "svc_gscv.fit(train_data_imp, train_labels)\n",
    "nn = svc_gscv.best_params_\n",
    "\n",
    "# find accuracy\n",
    "svc = SVC(C=nn['C'])\n",
    "svc.fit(train_data_imp, train_labels)\n",
    "svc_pred = svc.predict(val_data_imp)\n",
    "accuracy_score(val_labels, svc_pred)\n",
    "f1_score(val_labels, svc_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2934220792557482"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decision tree\n",
    "\n",
    "# grid search\n",
    "dt = DecisionTreeClassifier()\n",
    "param_grid = {'max_depth': np.arange(1, 25)}\n",
    "dt_gscv = GridSearchCV(dt, param_grid, cv=5)\n",
    "dt_gscv.fit(train_data_imp, train_labels)\n",
    "nn = dt_gscv.best_params_\n",
    "\n",
    "# find accuracy\n",
    "dt = DecisionTreeClassifier(max_depth=nn['max_depth'])\n",
    "dt.fit(train_data_imp, train_labels)\n",
    "dt_pred = dt.predict(val_data_imp)\n",
    "accuracy_score(val_labels, dt_pred)\n",
    "f1_score(val_labels, dt_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40401242807940496"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient boosting\n",
    "\n",
    "# grid search\n",
    "gb = GradientBoostingClassifier()\n",
    "param_grid = {'n_estimators': np.arange(1, 25)} \n",
    "gb_gscv = GridSearchCV(gb, param_grid, cv=5)\n",
    "gb_gscv.fit(train_data_imp, train_labels)\n",
    "nn = gb_gscv.best_params_\n",
    "\n",
    "# find accuracy\n",
    "gb = GradientBoostingClassifier(n_estimators=nn['n_estimators'])\n",
    "gb.fit(train_data_imp, train_labels)\n",
    "gb_pred = gb.predict(val_data_imp)\n",
    "accuracy_score(val_labels, gb_pred)\n",
    "f1_score(val_labels, gb_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39186202686202687"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neural network\n",
    "\n",
    "# grid search\n",
    "nn = MLPClassifier(max_iter=10000)\n",
    "param_grid = {'hidden_layer_sizes': np.arange(1, 25)}\n",
    "nn_gscv = GridSearchCV(nn, param_grid, cv=5)\n",
    "nn_gscv.fit(train_data_imp, train_labels)\n",
    "nn = nn_gscv.best_params_\n",
    "\n",
    "# find accuracy\n",
    "nn = MLPClassifier(hidden_layer_sizes=nn['hidden_layer_sizes'], max_iter=10000)\n",
    "nn.fit(train_data_imp, train_labels)\n",
    "nn_pred = nn.predict(val_data_imp)\n",
    "accuracy_score(val_labels, nn_pred)\n",
    "f1_score(val_labels, nn_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation to output f1-score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(knn, train_data_imp, train_labels, cv=5)\n",
    "cross_val_score(logreg, train_data_imp, train_labels, cv=5)\n",
    "cross_val_score(rf, train_data_imp, train_labels, cv=5)\n",
    "cross_val_score(svc, train_data_imp, train_labels, cv=5)\n",
    "cross_val_score(dt, train_data_imp, train_labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final: random forests\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=est)\n",
    "all_labels = np.concatenate((train_labels, val_labels))\n",
    "rf.fit(all_imp, all_labels)\n",
    "rf_pred = rf.predict(test_data_imp)\n",
    "\n",
    "# write to csv\n",
    "rf_pred = pd.DataFrame(np.array([(i + 1, v) for i, v in enumerate(rf_pred)]))\n",
    "rf_pred.columns = ['Id', 'Category']\n",
    "rf_pred.to_csv('rf_pred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
