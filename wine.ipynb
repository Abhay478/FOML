{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the csv file\n",
    "red_wine_data = pd.read_csv('wine+quality/winequality-red.csv', sep=';')\n",
    "white_wine_data = pd.read_csv('wine+quality/winequality-white.csv', sep=';')\n",
    "\n",
    "# Add a column to the data to indicate the type of wine\n",
    "red_wine_data['type'] = 0\n",
    "white_wine_data['type'] = 1\n",
    "\n",
    "# Combine the two datasets into one\n",
    "wine_data = pd.concat([red_wine_data, white_wine_data])\n",
    "# print(wine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to remove correlated features using sklearn\n",
    "# def remove_correlated_features(data: pd.DataFrame, nf=5, p=False):\n",
    "#     from sklearn.feature_selection import SelectKBest\n",
    "#     from sklearn.feature_selection import chi2\n",
    "    \n",
    "#     X = data.drop('quality', axis=1)\n",
    "#     y = data['quality']\n",
    "\n",
    "#     # extract top nf best features\n",
    "#     bestfeatures = SelectKBest(score_func=chi2, k=nf)\n",
    "#     fit = bestfeatures.fit(X,y)\n",
    "#     dfscores = pd.DataFrame(fit.scores_)\n",
    "#     dfcolumns = pd.DataFrame(X.columns)\n",
    "#     # concat two dataframes for better visualization \n",
    "#     featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "#     featureScores.columns = ['Specs','Score']  # naming the dataframe columns\n",
    "#     if p:\n",
    "#         print(featureScores.nlargest(nf,'Score'))  # print nf best features\n",
    "\n",
    "#     junk = featureScores.nsmallest(len(featureScores)-nf,'Score')['Specs']\n",
    "#     # remove the correlated features\n",
    "#     return data.drop(junk, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    # sigmoid function, 1 / (1 + exp(-t))\n",
    "    # stable computation\n",
    "    idx = t > 0\n",
    "    out = np.zeros_like(t)\n",
    "    out[idx] = 1. / (1 + np.exp(-t[idx]))\n",
    "    exp_t = np.exp(t[~idx])\n",
    "    out[~idx] = exp_t / (1. + exp_t)\n",
    "    return out\n",
    "\n",
    "\n",
    "def log_loss(Z):\n",
    "    # stable computation of the logistic loss\n",
    "    idx = Z > 0\n",
    "    out = np.zeros_like(Z)\n",
    "    out[idx] = np.log(1 + np.exp(-Z[idx]))\n",
    "    out[~idx] = (-Z[~idx] + np.log(1 + np.exp(Z[~idx])))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def obj_margin(x0, X, y, alpha, n_class, weights, L, sample_weight):\n",
    "    w = x0[:X.shape[1]]\n",
    "    c = x0[X.shape[1]:]\n",
    "    theta = L.dot(c)\n",
    "    loss_fd = weights[y]\n",
    "\n",
    "    Xw = X.dot(w)\n",
    "    Alpha = theta[:, None] - Xw  # (n_class - 1, n_samples)\n",
    "    S = np.sign(np.arange(n_class - 1)[:, None] - y + 0.5)\n",
    "\n",
    "    err = loss_fd.T * log_loss(S * Alpha)\n",
    "    if sample_weight is not None:\n",
    "        err *= sample_weight\n",
    "    obj = np.sum(err)\n",
    "    obj += alpha * 0.5 * (np.dot(w, w))\n",
    "    return obj\n",
    "\n",
    "\n",
    "def grad_margin(x0, X, y, alpha, n_class, weights, L, sample_weight):\n",
    "    w = x0[:X.shape[1]]\n",
    "    c = x0[X.shape[1]:]\n",
    "    theta = L.dot(c)\n",
    "    loss_fd = weights[y]\n",
    "\n",
    "    Xw = X.dot(w)\n",
    "    Alpha = theta[:, None] - Xw  # (n_class - 1, n_samples)\n",
    "    S = np.sign(np.arange(n_class - 1)[:, None] - y + 0.5)\n",
    "\n",
    "    Sigma = S * loss_fd.T * sigmoid(-S * Alpha)\n",
    "    if sample_weight is not None:\n",
    "        Sigma *= sample_weight\n",
    "\n",
    "    grad_w = X.T.dot(Sigma.sum(0)) + alpha * w\n",
    "\n",
    "    grad_theta = -Sigma.sum(1)\n",
    "    grad_c = L.T.dot(grad_theta)\n",
    "    return np.concatenate((grad_w, grad_c), axis=0)\n",
    "\n",
    "\n",
    "def threshold_fit(X, y, alpha, n_class, mode='AE',\n",
    "                  max_iter=1000, verbose=False, tol=1e-12,\n",
    "                  sample_weight=None):\n",
    "    \n",
    "    from sklearn.utils.validation import check_X_y\n",
    "    X, y = check_X_y(X, y, accept_sparse='csr')\n",
    "    unique_y = np.sort(np.unique(y))\n",
    "    if not np.all(unique_y == np.arange(unique_y.size)):\n",
    "        raise ValueError(\n",
    "            'Values in y must be %s, instead got %s'\n",
    "            % (np.arange(unique_y.size), unique_y))\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # convert from c to theta\n",
    "    L = np.zeros((n_class - 1, n_class - 1))\n",
    "    L[np.tril_indices(n_class-1)] = 1.\n",
    "\n",
    "    if mode == 'AE':\n",
    "        # loss forward difference\n",
    "        loss_fd = np.ones((n_class, n_class - 1))\n",
    "    elif mode == '0-1':\n",
    "        loss_fd = np.diag(np.ones(n_class - 1)) + \\\n",
    "            np.diag(np.ones(n_class - 2), k=-1)\n",
    "        loss_fd = np.vstack((loss_fd, np.zeros(n_class - 1)))\n",
    "        loss_fd[-1, -1] = 1  # border case\n",
    "    elif mode == 'SE':\n",
    "        a = np.arange(n_class-1)\n",
    "        b = np.arange(n_class)\n",
    "        loss_fd = np.abs((a - b[:, None])**2 - (a - b[:, None]+1)**2)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    x0 = np.zeros(n_features + n_class - 1)\n",
    "    x0[X.shape[1]:] = np.arange(n_class - 1)\n",
    "    options = {'maxiter' : max_iter, 'disp': verbose}\n",
    "    if n_class > 2:\n",
    "        bounds = [(None, None)] * (n_features + 1) + \\\n",
    "                 [(0, None)] * (n_class - 2)\n",
    "    else:\n",
    "        bounds = None\n",
    "\n",
    "    sol = optimize.minimize(obj_margin, x0, method='L-BFGS-B',\n",
    "        jac=grad_margin, bounds=bounds, options=options,\n",
    "        args=(X, y, alpha, n_class, loss_fd, L, sample_weight),\n",
    "        tol=tol)\n",
    "    if verbose and not sol.success:\n",
    "        print(sol.message)\n",
    "\n",
    "    w, c = sol.x[:X.shape[1]], sol.x[X.shape[1]:]\n",
    "    theta = L.dot(c)\n",
    "    return w, theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is based off of mord.LogisticAT. A few unused methods were removed, along with some error-checking.\n",
    "class CustomOrdinal:\n",
    "    def __init__(self, alpha=1., max_iter=1000) -> None:\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # The below two variables were fields of the class in mord. This is not necessary here.\n",
    "        classes = np.unique(y)\n",
    "        n_class = classes.max() - classes.min() + 1\n",
    "\n",
    "        # Added this field instead. Represents the offset of the classes.\n",
    "        self.shift = classes.min()\n",
    "        y_shift = y - y.min()\n",
    "\n",
    "        self.coef, self.theta = threshold_fit(\n",
    "            X, \n",
    "            y_shift, \n",
    "            self.alpha, \n",
    "            n_class, \n",
    "            max_iter=self.max_iter,\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.sum(\n",
    "            self.theta[:, None] - np.asarray(X.dot(self.coef)) < 0, \n",
    "            axis=0\n",
    "        ).astype(int) + self.shift\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function for ordinal regression of the quality column from selected features using the mord package \n",
    "# Low accuracy, about the same as logistic regression from sklearn\n",
    "# Eh. Not great.\n",
    "# Turns out 'not great' is good enough, lol.\n",
    "def ordinal_regression_custom(data: pd.DataFrame, nf=5):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # remove correlated features\n",
    "    # data = remove_correlated_features(data, nf=nf, p=False)\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X = data.drop(['quality'], axis=1) # everything except the quality column\n",
    "    # print(X)\n",
    "    y = data['quality'] # the quality column\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "    # scale the data - this speeds up the computation.\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    scaler.fit(X_test)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    # fit the model using mord multiclass classifier\n",
    "    model = CustomOrdinal()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # print('Accuracy')\n",
    "    out = pd.DataFrame(columns=['Accuracy', 'Pseudo-Accuracy'], index=['Ordinal', 'Linear'])\n",
    "\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    out['Accuracy']['Ordinal'] = accuracy * 100.0\n",
    "\n",
    "    # Sometimes the output may be off by 1. \n",
    "    # New metric is okay with off-by-one errors.\n",
    "    # With ordinal data, if the output is within some small range of the actual value, \n",
    "    # it may still be considered correct.\n",
    "    pseudo_accuracy = np.sum(np.abs(y_test - y_pred) <= 1) / len(y_test)\n",
    "    # print(\"Pseudo-Accuracy: %.2f%%\" % (pseudo_accuracy * 100.0))\n",
    "    out['Pseudo-Accuracy']['Ordinal'] = pseudo_accuracy * 100.0\n",
    "\n",
    "    # classification report\n",
    "    print('Classification Report')\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = np.sum(y_pred // 1 == y_test) / len(y_test)\n",
    "    # print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    out['Accuracy']['Linear'] = accuracy * 100.0\n",
    "    pseudo_accuracy = np.sum(np.abs(y_test - y_pred) <= 1) / len(y_test)\n",
    "    # print(\"Pseudo-Accuracy: %.2f%%\" % (pseudo_accuracy * 100.0))\n",
    "    out['Pseudo-Accuracy']['Linear'] = pseudo_accuracy * 100.0\n",
    "\n",
    "\n",
    "\n",
    "    print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.33      0.02      0.04        43\n",
      "           5       0.61      0.50      0.55       442\n",
      "           6       0.48      0.73      0.58       547\n",
      "           7       0.46      0.23      0.31       220\n",
      "           8       0.00      0.00      0.00        41\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.52      1300\n",
      "   macro avg       0.27      0.21      0.21      1300\n",
      "weighted avg       0.50      0.52      0.48      1300\n",
      "\n",
      "          Accuracy Pseudo-Accuracy\n",
      "Ordinal  51.615385            95.0\n",
      "Linear   44.769231       84.538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "ordinal_regression_custom(wine_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
