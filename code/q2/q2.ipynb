{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the csv file\n",
    "red_wine_data = pd.read_csv('winequality-red.csv', sep=';')\n",
    "white_wine_data = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Add a column to the data to indicate the type of wine\n",
    "red_wine_data['type'] = 0\n",
    "white_wine_data['type'] = 1\n",
    "\n",
    "# Combine the two datasets into one\n",
    "wine_data = pd.concat([red_wine_data, white_wine_data])\n",
    "# print(wine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='quality', ylabel='Count'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data in a histogram seaborn\n",
    "import seaborn as sn\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "sn.histplot(wine_data['quality'], bins=7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFunction to remove correlated features using sklearn\\nUnnecessary, all features are useful\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Function to remove correlated features using sklearn\n",
    "Unnecessary, all features are useful\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# def remove_correlated_features(data: pd.DataFrame, nf=5, p=False):\n",
    "#     from sklearn.feature_selection import SelectKBest\n",
    "#     from sklearn.feature_selection import chi2\n",
    "    \n",
    "#     X = data.drop('quality', axis=1)\n",
    "#     y = data['quality']\n",
    "\n",
    "#     # extract top nf best features\n",
    "#     bestfeatures = SelectKBest(score_func=chi2, k=nf)\n",
    "#     fit = bestfeatures.fit(X,y)\n",
    "#     dfscores = pd.DataFrame(fit.scores_)\n",
    "#     dfcolumns = pd.DataFrame(X.columns)\n",
    "#     # concat two dataframes for better visualization \n",
    "#     featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "#     featureScores.columns = ['Specs','Score']  # naming the dataframe columns\n",
    "#     if p:\n",
    "#         print(featureScores.nlargest(nf,'Score'))  # print nf best features\n",
    "#     junk = featureScores.nsmallest(len(featureScores)-nf,'Score')['Specs']\n",
    "#     # remove the correlated features\n",
    "#     return data.drop(junk, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImplementation of Ordinal Regression using the Threshold Model\\n\\nAbandoned in favour of package, as the question says we can indeed use packages for ordinal and \\nlinear regression\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implementation of Ordinal Regression using the Threshold Model\n",
    "\n",
    "Abandoned in favour of the mord package, as the question says we can indeed use packages for ordinal and \n",
    "linear regression\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# def sigmoid(t):\n",
    "#     # sigmoid function, 1 / (1 + exp(-t))\n",
    "#     # stable computation\n",
    "#     idx = t > 0\n",
    "#     out = np.zeros_like(t)\n",
    "#     out[idx] = 1. / (1 + np.exp(-t[idx]))\n",
    "#     exp_t = np.exp(t[~idx])\n",
    "#     out[~idx] = exp_t / (1. + exp_t)\n",
    "#     return out\n",
    "\n",
    "\n",
    "# def log_loss(Z):\n",
    "#     # stable computation of the logistic loss\n",
    "#     idx = Z > 0\n",
    "#     out = np.zeros_like(Z)\n",
    "#     out[idx] = np.log(1 + np.exp(-Z[idx]))\n",
    "#     out[~idx] = (-Z[~idx] + np.log(1 + np.exp(Z[~idx])))\n",
    "#     return out\n",
    "\n",
    "\n",
    "# def obj_margin(x0, X, y, alpha, n_class, weights, L, sample_weight):\n",
    "#     w = x0[:X.shape[1]]\n",
    "#     c = x0[X.shape[1]:]\n",
    "#     theta = L.dot(c)\n",
    "#     loss_fd = weights[y]\n",
    "#     Xw = X.dot(w)\n",
    "#     Alpha = theta[:, None] - Xw  # (n_class - 1, n_samples)\n",
    "#     S = np.sign(np.arange(n_class - 1)[:, None] - y + 0.5)\n",
    "#     err = loss_fd.T * log_loss(S * Alpha)\n",
    "#     if sample_weight is not None:\n",
    "#         err *= sample_weight\n",
    "#     obj = np.sum(err)\n",
    "#     obj += alpha * 0.5 * (np.dot(w, w))\n",
    "#     return obj\n",
    "\n",
    "\n",
    "# def grad_margin(x0, X, y, alpha, n_class, weights, L, sample_weight):\n",
    "#     w = x0[:X.shape[1]]\n",
    "#     c = x0[X.shape[1]:]\n",
    "#     theta = L.dot(c)\n",
    "#     loss_fd = weights[y]\n",
    "#     Xw = X.dot(w)\n",
    "#     Alpha = theta[:, None] - Xw  # (n_class - 1, n_samples)\n",
    "#     S = np.sign(np.arange(n_class - 1)[:, None] - y + 0.5)\n",
    "#     Sigma = S * loss_fd.T * sigmoid(-S * Alpha)\n",
    "#     if sample_weight is not None:\n",
    "#         Sigma *= sample_weight\n",
    "#     grad_w = X.T.dot(Sigma.sum(0)) + alpha * w\n",
    "#     grad_theta = -Sigma.sum(1)\n",
    "#     grad_c = L.T.dot(grad_theta)\n",
    "#     return np.concatenate((grad_w, grad_c), axis=0)\n",
    "\n",
    "\n",
    "# def threshold_fit(X, y, alpha, n_class, mode='AE',\n",
    "#                   max_iter=1000, verbose=False, tol=1e-12,\n",
    "#                   sample_weight=None):\n",
    "#     from sklearn.utils.validation import check_X_y\n",
    "#     X, y = check_X_y(X, y, accept_sparse='csr')\n",
    "#     unique_y = np.sort(np.unique(y))\n",
    "#     if not np.all(unique_y == np.arange(unique_y.size)):\n",
    "#         raise ValueError(\n",
    "#             'Values in y must be %s, instead got %s'\n",
    "#             % (np.arange(unique_y.size), unique_y))\n",
    "#     n_samples, n_features = X.shape\n",
    "#     # convert from c to theta\n",
    "#     L = np.zeros((n_class - 1, n_class - 1))\n",
    "#     L[np.tril_indices(n_class-1)] = 1.\n",
    "#     if mode == 'AE':\n",
    "#         # loss forward difference\n",
    "#         loss_fd = np.ones((n_class, n_class - 1))\n",
    "#     elif mode == '0-1':\n",
    "#         loss_fd = np.diag(np.ones(n_class - 1)) + \\\n",
    "#             np.diag(np.ones(n_class - 2), k=-1)\n",
    "#         loss_fd = np.vstack((loss_fd, np.zeros(n_class - 1)))\n",
    "#         loss_fd[-1, -1] = 1  # border case\n",
    "#     elif mode == 'SE':\n",
    "#         a = np.arange(n_class-1)\n",
    "#         b = np.arange(n_class)\n",
    "#         loss_fd = np.abs((a - b[:, None])**2 - (a - b[:, None]+1)**2)\n",
    "#     else:\n",
    "#         raise NotImplementedError\n",
    "#     x0 = np.zeros(n_features + n_class - 1)\n",
    "#     x0[X.shape[1]:] = np.arange(n_class - 1)\n",
    "#     options = {'maxiter' : max_iter, 'disp': verbose}\n",
    "#     if n_class > 2:\n",
    "#         bounds = [(None, None)] * (n_features + 1) + \\\n",
    "#                  [(0, None)] * (n_class - 2)\n",
    "#     else:\n",
    "#         bounds = None\n",
    "#     sol = optimize.minimize(obj_margin, x0, method='L-BFGS-B',\n",
    "#         jac=grad_margin, bounds=bounds, options=options,\n",
    "#         args=(X, y, alpha, n_class, loss_fd, L, sample_weight),\n",
    "#         tol=tol)\n",
    "#     if verbose and not sol.success:\n",
    "#         print(sol.message)\n",
    "#     w, c = sol.x[:X.shape[1]], sol.x[X.shape[1]:]\n",
    "#     theta = L.dot(c)\n",
    "#     return w, theta\n",
    "\n",
    "\n",
    "# # This is based off of mord.LogisticAT. A few unused methods were removed, along with some error-checking.\n",
    "# class CustomOrdinal:\n",
    "#     def __init__(self, alpha=1., max_iter=1000) -> None:\n",
    "#         self.alpha = alpha\n",
    "#         self.max_iter = max_iter\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         # The below two variables were fields of the class in mord. This is not necessary here.\n",
    "#         classes = np.unique(y)\n",
    "#         n_class = classes.max() - classes.min() + 1\n",
    "#         # Added this field instead. Represents the offset of the classes.\n",
    "#         self.shift = classes.min()\n",
    "#         y_shift = y - y.min()\n",
    "#         self.coef, self.theta = threshold_fit(\n",
    "#             X, \n",
    "#             y_shift, \n",
    "#             self.alpha, \n",
    "#             n_class, \n",
    "#             max_iter=self.max_iter,\n",
    "#         )\n",
    "#         return self\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         return np.sum(\n",
    "#             self.theta[:, None] - np.asarray(X.dot(self.coef)) < 0, \n",
    "#             axis=0\n",
    "#         ).astype(int) + self.shift\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function for ordinal regression of the quality column from selected features using the mord package \n",
    "# Low accuracy, about the same as logistic regression from sklearn\n",
    "# Eh. Not great.\n",
    "# Turns out 'not great' is good enough, lol.\n",
    "def ordinal_regression_custom(data: pd.DataFrame, nf=5):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from mord import LogisticAT\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X = data.drop(['quality'], axis=1) # everything except the quality column\n",
    "    # print(X)\n",
    "    y = data['quality'] # the quality column\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "    # scale the data - this speeds up the computation.\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    scaler.fit(X_test)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    # fit the model using mord multiclass classifier\n",
    "    model = LogisticAT()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # print('Accuracy')\n",
    "    out = pd.DataFrame(columns=['Accuracy', 'Pseudo-Accuracy'], index=['Ordinal', 'Linear'])\n",
    "\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    out['Accuracy']['Ordinal'] = accuracy * 100.0\n",
    "\n",
    "    # Sometimes the output may be off by 1. \n",
    "    # New metric is okay with off-by-one errors.\n",
    "    # With ordinal data, if the output is within some small range of the actual value, \n",
    "    # it may still be considered correct.\n",
    "    pseudo_accuracy = np.sum(np.abs(y_test - y_pred) <= 1) / len(y_test)\n",
    "    out['Pseudo-Accuracy']['Ordinal'] = pseudo_accuracy * 100.0\n",
    "\n",
    "\n",
    "    # Linear Regression\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = np.sum(np.rint(y_pred) == y_test) / len(y_test)\n",
    "    out['Accuracy']['Linear'] = accuracy * 100.0\n",
    "    pseudo_accuracy = np.sum(np.abs(y_test - np.rint(y_pred)) <= 1) / len(y_test)\n",
    "    out['Pseudo-Accuracy']['Linear'] = pseudo_accuracy * 100.0\n",
    "\n",
    "\n",
    "\n",
    "    print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Accuracy Pseudo-Accuracy\n",
      "Ordinal  53.384615       94.769231\n",
      "Linear   53.230769       94.846154\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "ordinal_regression_custom(wine_data)\n",
    "\n",
    "# Output:\n",
    "#           Accuracy Pseudo-Accuracy\n",
    "# Ordinal    <?????>         <?????>\n",
    "# Linear     <?????>         <?????>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "## Relative performance of Linear and Ordinal Regression\n",
    "\n",
    "- Both linear and ordinar regression are yielding highly similar results in accuracy as well as pseudoaccuracy\n",
    "- This indicates that the dataset could, in fact, be modeled by linear regression, and that the non-linearities are not significant enough to warrant the use of a more complex model\n",
    "\n",
    "## Metrics\n",
    "\n",
    "Here, we have used the following metrics:\n",
    "  - Accuracy: The percentage of correctly classified samples\n",
    "  - Pseudo-Accuracy: The percentage of samples classified to within one ordinal caregory of the correct output. For example, if the correct output is 3, then Pseudo-Accuracy is the percentage of samples classified as 2, 3 or 4\n",
    "\n",
    "### Note: \n",
    "In linear regression, the output is rounded off to the nearest integer and then compared to the correct output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
